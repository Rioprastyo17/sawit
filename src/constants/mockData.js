// File: src/constants/mockData.js (VERSI JAVASCRIPT MURNI)

// Karena ini file .js, kita tidak bisa menggunakan 'interface' atau tipe data.
export const citations = [
  {
    id: 1,
    quote: "Penyidik forensik menemukan bahwa penyerang telah menggunakan prompt jailbreak, input yang dibuat khusus yang dirancang untuk melewati filter keamanan AI dan memunculkan informasi yang dibatasi, untuk mendapatkan informasi dari Gemini tentang cara membuat ransomware.",
    author: "Xie, Yueqi, et al.",
    year: 2023,
    bibliography: "Xie, Yueqi, Yi, Jingwei, Shao, Jiawei, Curl, Justin, Lyu, Linjian, Chen, Qifeng, Xie, Xing, Wu, Fangzhao. (2023). Defending ChatGPT against jailbreak attack via self-reminders. Nat. Mach Intell. 5 (12), 1486-1496."
  },
  {
    id: 2,
    quote: "Catatan penggunaan Gemini disimpan di log Aktivitas Saya yang dikelola oleh Google, dan catatan penggunaan ini dapat diunduh menggunakan ‘Google Takeout’.",
    author: "Akinbi, Alex, et al.",
    year: 2020,
    bibliography: "Akinbi, Alex, Berry, Thomas. (2020). Forensic investigation of Google assistant. SN Comput. Sci. 1 (5), 272."
  },
  // ... (data lainnya sama)
  {
    id: 3,
    quote: "Pada tanggal 2 Juli, sebulan setelah aplikasi desktop dirilis, muncul masalah bahwa data percakapan disimpan dalam teks biasa.",
    author: "Philips, Jason",
    year: 2024,
    bibliography: "Philips, Jason. (2024). ChatGPT desktop app for Mac has a major security flaw that could expose user data. Macworld. https://www.macworld.com/article/2386267/chatgpt-mac-sandbox-security-flaw-apple-intelligence.html."
  },
  {
    id: 4,
    quote: "Model bahasa besar dilatih pada kumpulan data besar teks dan kode, yang mungkin mencakup informasi pribadi atau sensitif.",
    author: "Weidinger, Laura, et al.",
    year: 2021,
    bibliography: "Weidinger, L., Mellor, J., Rauh, M., Griffin, C., Uesato, J., Huang, P. S., ... & Gabriel, I. (2021). Ethical and social risks of harm from Language Models. arXiv preprint arXiv:2112.04359."
  }
];